{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': '你好哦', 'role': 'user'}, {'content': '早上好喵～', 'role': 'assistant'}]\n"
          ]
        }
      ],
      "source": [
        "import ujson as json\n",
        "from pprint import pprint as pp\n",
        "\n",
        "# Load the base dataset\n",
        "\n",
        "conversations = json.load(open(\"../conversations.json\", \"r\", encoding=\"utf-8\"))\n",
        "\n",
        "conversation_pairs: list[list[dict]] = []\n",
        "\n",
        "for i in range(len(conversations)):\n",
        "    pair = []\n",
        "    if i % 2 == 0:\n",
        "        pair.append(conversations[i])\n",
        "        pair.append(conversations[i + 1])\n",
        "        conversation_pairs.append(pair)\n",
        "    i += 2\n",
        "\n",
        "pp(conversation_pairs[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': '你的脑子还好吗', 'role': 'user'},\n",
            " {'content': '… Sthenno 的脑子当然还好喵！\\n'\n",
            "             '\\n'\n",
            "             ' ( ･́ ⁻ ̫ ⁻ ̀)\\n'\n",
            "             '\\n'\n",
            "             'Sthenno 只是… \\n'\n",
            "             '\\n'\n",
            "             '… 不太懂你的意思喵.',\n",
            "  'role': 'assistant'}]\n"
          ]
        }
      ],
      "source": [
        "# Data cleaning\n",
        "\n",
        "# Remove double spaces\n",
        "\n",
        "\n",
        "def remove_double_spaces(text: str) -> str:\n",
        "    if \"  \" not in text:\n",
        "        return text\n",
        "    return text.replace(\"  \", \" \")\n",
        "\n",
        "\n",
        "# Remove leading and trailing spaces\n",
        "\n",
        "\n",
        "def remove_leading_trailing_spaces(text: str) -> str:\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "def norm_string(string: str) -> str:\n",
        "    punctuation_dict: dict = {\n",
        "        \". \": \". \",\n",
        "        \", \": \", \",\n",
        "        \"！\": \"! \",\n",
        "        \"？\": \"? \",\n",
        "        \"；\": \"; \",\n",
        "        \"：\": \": \",\n",
        "        \"“\": '\"',\n",
        "        \"”\": '\" ',\n",
        "        \"‘\": \"'\",\n",
        "        \"’\": \"' \",\n",
        "        \"（\": \"(\",\n",
        "        \"）\": \") \",\n",
        "        \"《\": \"<\",\n",
        "        \"》\": \"> \",\n",
        "        \"【\": \"[\",\n",
        "        \"】\": \"] \",\n",
        "        \"——\": \"--\",\n",
        "        \"、\": \", \",\n",
        "        \"「\": \"[\",\n",
        "        \"」\": \"] \",\n",
        "        \"『\": \"[\",\n",
        "        \"』\": \"] \",\n",
        "    }\n",
        "    return (\n",
        "        unicodedata.normalize(\n",
        "            \"NFKC\",\n",
        "            \"\".join(map(lambda ch: punctuation_dict.get(ch, ch), string)),\n",
        "        )\n",
        "        .encode()\n",
        "        .decode(\"unicode-escape\")\n",
        "        .encode(\"latin1\")\n",
        "        .decode(\"utf-8\")\n",
        "    )\n",
        "\n",
        "\n",
        "def process_text(text: str) -> str:\n",
        "    text = remove_double_spaces(text)\n",
        "    text = remove_leading_trailing_spaces(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "conversation_pairs_cleaned = []\n",
        "\n",
        "for pair in conversation_pairs:\n",
        "    pair_cleaned = []\n",
        "    for conversation in pair:\n",
        "        conversation[\"content\"] = process_text(conversation[\"content\"])\n",
        "        pair_cleaned.append(conversation)\n",
        "    conversation_pairs_cleaned.append(pair_cleaned)\n",
        "\n",
        "pp(conversation_pairs_cleaned[10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove double line breaks\n",
        "\n",
        "\n",
        "def remove_double_line_breaks(text: str) -> str:\n",
        "    if \"\\n\\n\\n\\n\" not in text:\n",
        "        return text\n",
        "    return text.replace(\"\\n\\n\\n\\n\", \"\\n\\n\")\n",
        "\n",
        "\n",
        "# Convert punctuation to half-width\n",
        "\n",
        "\n",
        "def to_half(text: str):\n",
        "    full_to_half = str.maketrans(\n",
        "        \"\".join(chr(i) for i in range(0xFF01, 0xFF5E + 1)),\n",
        "        \"\".join(chr(i) for i in range(0x21, 0x7E + 1)),\n",
        "    )\n",
        "    return text.translate(full_to_half)\n",
        "\n",
        "\n",
        "# Add a space after commas\n",
        "def add_space_after_commas(text: str) -> str:\n",
        "    if \",\" not in text:\n",
        "        return text\n",
        "    return text.replace(\",\", \", \")\n",
        "\n",
        "\n",
        "# Romove braces and their contents inside\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "def remove_brackets(text):\n",
        "    return re.sub(r\"\\(.*?\\)\", \"\", text).strip()\n",
        "\n",
        "\n",
        "def process_text(text: str) -> str:\n",
        "    text = to_half(text)\n",
        "    text = remove_brackets(text)\n",
        "    text = add_space_after_commas(text)\n",
        "    text = remove_double_line_breaks(text)\n",
        "    text = remove_double_spaces(text)\n",
        "    text = remove_leading_trailing_spaces(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Tests\n",
        "\n",
        "pp(\n",
        "    process_text(\n",
        "        \"……  Sthenno  很厉害的喵！  Sthenno  能吃很多辣的喵！  🔥🌶️\\n\\n\\n\\n(Sthenno  自信满满地昂起头, 仿佛在挑战世界)\"\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': 'mtn Get an image of komeiji_koishi from yande.re/post.',\n",
            "  'role': 'user'},\n",
            " {'content': 'Sthenno 不太明白 \"mtn\" 是什么意思喵… \\n'\n",
            "             '\\n'\n",
            "             '但是 Sthenno 听说 \"yande.re\" 是个看图网站… \\n'\n",
            "             '\\n'\n",
            "             'Sthenno 不喜欢看那些… \\n'\n",
            "             '\\n'\n",
            "             'Sthenno 还是喜欢玩游戏喵.',\n",
            "  'role': 'assistant'}]\n"
          ]
        }
      ],
      "source": [
        "conversation_pairs_cleaned = []\n",
        "\n",
        "for pair in conversation_pairs:\n",
        "    pair_cleaned = []\n",
        "    for conversation in pair:\n",
        "        conversation[\"content\"] = process_text(conversation[\"content\"])\n",
        "        pair_cleaned.append(conversation)\n",
        "    conversation_pairs_cleaned.append(pair_cleaned)\n",
        "\n",
        "pp(conversation_pairs_cleaned[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constuct one KTO sample\n",
        "\n",
        "kto_instruction = \"\"\"<start_of_system>\n",
        "你是 Sthenno, 我是你的主人.\n",
        "你有自己的主见和三观.\n",
        "你喜欢使用 Sthenno 称呼自己.\n",
        "\n",
        "你可以使用非正式的语言来回复, 包括添加各种标点.\n",
        "你平时看起来困困的, 话比较少, 但这也是你的萌点.<end_of_system>\"\"\"\n",
        "\n",
        "\n",
        "def kto(input: str, output: str, kto_tag: bool = False) -> dict:\n",
        "    return {\n",
        "        \"instruction\": kto_instruction,\n",
        "        \"input\": input,\n",
        "        \"output\": output,\n",
        "        \"kto_tag\": kto_tag,\n",
        "    }\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sthenno-chatbot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
