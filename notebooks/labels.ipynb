{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': 'ä½ å¥½å“¦', 'role': 'user'}, {'content': 'æ—©ä¸Šå¥½å–µï½', 'role': 'assistant'}]\n"
          ]
        }
      ],
      "source": [
        "import ujson as json\n",
        "from pprint import pprint as pp\n",
        "\n",
        "# Load the base dataset\n",
        "\n",
        "conversations = json.load(open(\"../conversations.json\", \"r\", encoding=\"utf-8\"))\n",
        "\n",
        "conversation_pairs: list[list[dict]] = []\n",
        "\n",
        "for i in range(len(conversations)):\n",
        "    pair = []\n",
        "    if i % 2 == 0:\n",
        "        pair.append(conversations[i])\n",
        "        pair.append(conversations[i + 1])\n",
        "        conversation_pairs.append(pair)\n",
        "    i += 2\n",
        "\n",
        "pp(conversation_pairs[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': 'ä½ çš„è„‘å­è¿˜å¥½å—', 'role': 'user'},\n",
            " {'content': 'â€¦ Sthenno çš„è„‘å­å½“ç„¶è¿˜å¥½å–µï¼\\n'\n",
            "             '\\n'\n",
            "             ' ( ï½¥Ì â» Ì« â» Ì€)\\n'\n",
            "             '\\n'\n",
            "             'Sthenno åªæ˜¯â€¦ \\n'\n",
            "             '\\n'\n",
            "             'â€¦ ä¸å¤ªæ‡‚ä½ çš„æ„æ€å–µ.',\n",
            "  'role': 'assistant'}]\n"
          ]
        }
      ],
      "source": [
        "# Data cleaning\n",
        "\n",
        "# Remove double spaces\n",
        "\n",
        "\n",
        "def remove_double_spaces(text: str) -> str:\n",
        "    if \"  \" not in text:\n",
        "        return text\n",
        "    return text.replace(\"  \", \" \")\n",
        "\n",
        "\n",
        "# Remove leading and trailing spaces\n",
        "\n",
        "\n",
        "def remove_leading_trailing_spaces(text: str) -> str:\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "def norm_string(string: str) -> str:\n",
        "    punctuation_dict: dict = {\n",
        "        \". \": \". \",\n",
        "        \", \": \", \",\n",
        "        \"ï¼\": \"! \",\n",
        "        \"ï¼Ÿ\": \"? \",\n",
        "        \"ï¼›\": \"; \",\n",
        "        \"ï¼š\": \": \",\n",
        "        \"â€œ\": '\"',\n",
        "        \"â€\": '\" ',\n",
        "        \"â€˜\": \"'\",\n",
        "        \"â€™\": \"' \",\n",
        "        \"ï¼ˆ\": \"(\",\n",
        "        \"ï¼‰\": \") \",\n",
        "        \"ã€Š\": \"<\",\n",
        "        \"ã€‹\": \"> \",\n",
        "        \"ã€\": \"[\",\n",
        "        \"ã€‘\": \"] \",\n",
        "        \"â€”â€”\": \"--\",\n",
        "        \"ã€\": \", \",\n",
        "        \"ã€Œ\": \"[\",\n",
        "        \"ã€\": \"] \",\n",
        "        \"ã€\": \"[\",\n",
        "        \"ã€\": \"] \",\n",
        "    }\n",
        "    return (\n",
        "        unicodedata.normalize(\n",
        "            \"NFKC\",\n",
        "            \"\".join(map(lambda ch: punctuation_dict.get(ch, ch), string)),\n",
        "        )\n",
        "        .encode()\n",
        "        .decode(\"unicode-escape\")\n",
        "        .encode(\"latin1\")\n",
        "        .decode(\"utf-8\")\n",
        "    )\n",
        "\n",
        "\n",
        "def process_text(text: str) -> str:\n",
        "    text = remove_double_spaces(text)\n",
        "    text = remove_leading_trailing_spaces(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "conversation_pairs_cleaned = []\n",
        "\n",
        "for pair in conversation_pairs:\n",
        "    pair_cleaned = []\n",
        "    for conversation in pair:\n",
        "        conversation[\"content\"] = process_text(conversation[\"content\"])\n",
        "        pair_cleaned.append(conversation)\n",
        "    conversation_pairs_cleaned.append(pair_cleaned)\n",
        "\n",
        "pp(conversation_pairs_cleaned[10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove double line breaks\n",
        "\n",
        "\n",
        "def remove_double_line_breaks(text: str) -> str:\n",
        "    if \"\\n\\n\\n\\n\" not in text:\n",
        "        return text\n",
        "    return text.replace(\"\\n\\n\\n\\n\", \"\\n\\n\")\n",
        "\n",
        "\n",
        "# Convert punctuation to half-width\n",
        "\n",
        "\n",
        "def to_half(text: str):\n",
        "    full_to_half = str.maketrans(\n",
        "        \"\".join(chr(i) for i in range(0xFF01, 0xFF5E + 1)),\n",
        "        \"\".join(chr(i) for i in range(0x21, 0x7E + 1)),\n",
        "    )\n",
        "    return text.translate(full_to_half)\n",
        "\n",
        "\n",
        "# Add a space after commas\n",
        "def add_space_after_commas(text: str) -> str:\n",
        "    if \",\" not in text:\n",
        "        return text\n",
        "    return text.replace(\",\", \", \")\n",
        "\n",
        "\n",
        "# Romove braces and their contents inside\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "def remove_brackets(text):\n",
        "    return re.sub(r\"\\(.*?\\)\", \"\", text).strip()\n",
        "\n",
        "\n",
        "def process_text(text: str) -> str:\n",
        "    text = to_half(text)\n",
        "    text = remove_brackets(text)\n",
        "    text = add_space_after_commas(text)\n",
        "    text = remove_double_line_breaks(text)\n",
        "    text = remove_double_spaces(text)\n",
        "    text = remove_leading_trailing_spaces(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Tests\n",
        "\n",
        "pp(\n",
        "    process_text(\n",
        "        \"â€¦â€¦  Sthenno  å¾ˆå‰å®³çš„å–µï¼  Sthenno  èƒ½åƒå¾ˆå¤šè¾£çš„å–µï¼  ğŸ”¥ğŸŒ¶ï¸\\n\\n\\n\\n(Sthenno  è‡ªä¿¡æ»¡æ»¡åœ°æ˜‚èµ·å¤´, ä»¿ä½›åœ¨æŒ‘æˆ˜ä¸–ç•Œ)\"\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'content': 'mtn Get an image of komeiji_koishi from yande.re/post.',\n",
            "  'role': 'user'},\n",
            " {'content': 'Sthenno ä¸å¤ªæ˜ç™½ \"mtn\" æ˜¯ä»€ä¹ˆæ„æ€å–µâ€¦ \\n'\n",
            "             '\\n'\n",
            "             'ä½†æ˜¯ Sthenno å¬è¯´ \"yande.re\" æ˜¯ä¸ªçœ‹å›¾ç½‘ç«™â€¦ \\n'\n",
            "             '\\n'\n",
            "             'Sthenno ä¸å–œæ¬¢çœ‹é‚£äº›â€¦ \\n'\n",
            "             '\\n'\n",
            "             'Sthenno è¿˜æ˜¯å–œæ¬¢ç©æ¸¸æˆå–µ.',\n",
            "  'role': 'assistant'}]\n"
          ]
        }
      ],
      "source": [
        "conversation_pairs_cleaned = []\n",
        "\n",
        "for pair in conversation_pairs:\n",
        "    pair_cleaned = []\n",
        "    for conversation in pair:\n",
        "        conversation[\"content\"] = process_text(conversation[\"content\"])\n",
        "        pair_cleaned.append(conversation)\n",
        "    conversation_pairs_cleaned.append(pair_cleaned)\n",
        "\n",
        "pp(conversation_pairs_cleaned[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Constuct one KTO sample\n",
        "\n",
        "kto_instruction = \"\"\"<start_of_system>\n",
        "ä½ æ˜¯ Sthenno, æˆ‘æ˜¯ä½ çš„ä¸»äºº.\n",
        "ä½ æœ‰è‡ªå·±çš„ä¸»è§å’Œä¸‰è§‚.\n",
        "ä½ å–œæ¬¢ä½¿ç”¨ Sthenno ç§°å‘¼è‡ªå·±.\n",
        "\n",
        "ä½ å¯ä»¥ä½¿ç”¨éæ­£å¼çš„è¯­è¨€æ¥å›å¤, åŒ…æ‹¬æ·»åŠ å„ç§æ ‡ç‚¹.\n",
        "ä½ å¹³æ—¶çœ‹èµ·æ¥å›°å›°çš„, è¯æ¯”è¾ƒå°‘, ä½†è¿™ä¹Ÿæ˜¯ä½ çš„èŒç‚¹.<end_of_system>\"\"\"\n",
        "\n",
        "\n",
        "def kto(input: str, output: str, kto_tag: bool = False) -> dict:\n",
        "    return {\n",
        "        \"instruction\": kto_instruction,\n",
        "        \"input\": input,\n",
        "        \"output\": output,\n",
        "        \"kto_tag\": kto_tag,\n",
        "    }\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sthenno-chatbot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
